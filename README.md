# 108-1_IR-Ptt-HatePolitics-Project
鄉民稽查員 aka 網路生態觀察家系統

莊雅媜
R08725005

徐薇尹
R08725030

陳曦
R08725045

1. PURPOSE
　　由於時屆台灣四年一次的政治盛事「2020 中華民國總統選舉」，各個總統候選人／政治人物的支持者在台灣著名論壇 PTT 實業坊上的發言、活動較活躍，甚至有對岸勢力或特定黨派陣營購買 PTT 使用者帳號、策動「網軍」在 PTT 帶動風向的傳言，尤其造成 PTT 八卦版（Gossiping）、政黑版（HatePolitics）出現許多互相抹黑、筆戰、反串等亂象，版主群更是花費大量心力在刪除異常登入紀錄的帳號和相關爭議發文。
     有鑒於上述現象，我們希望能夠透過資訊檢索的技術找出 PTT 使用者的個人政治傾向／支持的政治人物，並單就推文次數統計來了解哪些使用者頻繁發布支持特定政治人物的言論，最後以網頁的形式來呈現我們的研究結果。
2. SOLUTION
　　根據上述所提及之動機與目的，我們希望能夠爬取 PTT 八卦版與政黑版其版上文章的推文作為資料來源，以現行的分類方法與機器學習方法建立出多標籤分類模型後，將其應用於 PTT 特定版上的文章推文，並統計各使用者推文次數和所屬標籤（立場），最後以網頁的方式呈現。我們主要以 Python 實作系統，以下我們將詳述整個專案的實作流程與技術內容。
2.1 資料取得：爬蟲
　　由於我們的分析目標是 PTT 八卦版與政黑版的鄉民推文，而這兩個看板屬於需成年才能觀看的頁面，因此我們使用了 Selenium 這個爬蟲套件來模擬瀏覽器的行為，在進入頁面前自動點選「已滿 18歲」的按鈕。
　　訓練集的部分，我們於 2019 年 12 月 14 號左右爬取 PTT 八卦版、PTT 政黑版上各 6,000 則推文（包含推文、噓文、箭頭），總共 12,000 則推文。
　　八卦版的部分由於文章內容五花八門，所以我們只選擇標題含有我們關心的政治議題的文章（見圖 1.），將一些符合 PTT 鄉民文化、用詞的單字設為關鍵字，政黑版的部分由於都是政治相關的文章，所以沒有特別過濾。

圖 1. 爬取 PTT 八卦版文章時的標題關鍵字
2.2 資料前處理
2.2.1 推文跨行處理
　　由於 PTT 中存在推文字數限制，所以如果某則留言太長，可能會被系統以多行的推文形式發布。如果同時也有其他使用者留言，可能就會造成推文打架（不同使用者的留言參雜在一起）的情況發生，若將一則長推文視為多則分開的推文，可能會造成文意不連續、很多單字被拆開的問題。對於這個部分，我們判斷同一使用者的留言若相差一分鐘內（含一分鐘）發布，則判斷為一則跨行的長推文，並且將它們連接在一起以還原原句。
2.2.2 自定義字典：使用 n-gram
　　由於PTT中使用者會大量使用一些流行語、鄉民術語，所以我們在移除推文中的無意義標點符號後（只保留一些我們認為有意義的標點符號，如：^^ 或 :) 有時會被用來表示「諷刺」的意味，… 有時會被用來表示「無言」或是「無奈」），使用了 n-gram 做字串的分割，其中 n = 2~7，n = 2~5主要處理中文字詞，n = 6~7處理英文字詞。
　　同時我們統計各字串的 term frequency，並以頻率大到小排序，刪除出現頻率比較小的單字後，以人工的方式檢查須將哪些「構成文意」的單字納入我們的自定義字典。另外我們也有手動加入一些訓練集當中沒有出現，但是在 PTT 中觀察到的單字。最後我們收錄了 2,024 個單字（見圖 2.），單字權重以出現頻率為主。並結合 Jieba（結巴）套件的字典一起在 Tokenization 的階段使用。

圖 2. 自定義字典中部分單字與權重
2.2.3 資料標籤：人工萃取法
　　由於 PTT 的推文用字比較口語化，且含有許多時事成分，所以我們認為使用人工來做 labeling 會達到比較精確的效果。
　　我們將每則推文標記三個標籤。第一個標籤代表該推文呈現的內容為正面／負面／中立，其值為 -2~2 之間，明顯正面給予 1，明顯負面給予 -1，委婉正面給予 2，委婉負面給予 -2，中立給予 0。第二與第三個標籤代表該推文呈現的立場，我們預設了 14 種立場（見圖 3.），若無明顯立場則視為中立（值為 0），所有標籤值為 0~14 之間。每則推文會有 0~2 個立場標籤，因為可能單則推文裡面沒有任何立場，也可能會同時有兩個立場（例如：「柯韓舔共一家親」代表留言者同時給予柯文哲和韓國瑜負面評價，即同時為柯黑和韓黑；又如「綠共超爛，票投韓總啦」則判定為韓粉和民進黨黑）。另外，如果是超過三種標籤以上（含三種）的狀況，我們以「人粉>人黑>黨粉>黨黑」的優先度處理，只保留兩個標籤。

圖 3. 第二、第三標籤種類圖

圖 4. 推文資料標籤
2.2.4 Tokenization & Stopwords
　　目前使用最普遍的 Python 中文斷詞套件為 Jieba，但由於 Jieba 原始開發版本為簡體中文，雖然亦支持繁體中文的斷詞，但簡繁的用詞大不相同，斷詞的效果會有所影響，因此我們另外安裝了 Jieba-tw（結巴斷詞台灣繁體特化版本）套件，該套件採用和原始 Jieba 相同的演算法，替換其詞庫及 HMM 機率表製作出針對台灣繁體的 Jieba 斷詞器。此外，由於我們的資料內容大量包含台灣政治相關文字語句、人名和網路流行用語，原始的 Jieba 字典無法認得這些詞彙，因此我們搭配 2.2.2 小節所整理的自定義字典和常見的中文 Stop words 來替推文做 Tokenization 等前處理。範例如下：
原句為：
後援會會長都自己說代表TMD黨的意志了，還是又要被seafood切割了？？
Tokenize & Stopword：
後援會|會長|說|代表|TMD|黨|意志| seafood|切割
2.3 多標籤分類模型
　　由於單一推文內容可能對於多個政治人物抱持不同的立場，很難單純從分析推文的正負面（圖 4. 第一個標籤）來分類推文者的立場，為了解決此問題，我們決定改對推文進行多標籤分類（Multi-Label Classification），能夠將一則推文分到多個類別（圖 4. 第二、三個標籤）。
　　我們將經過上述前處理過後的資料（推文內容）和人工標註好的標籤來做多標籤分類模型之訓練，並嘗試各種常見的分類方法，最後從中挑選表現最佳者（準確度最高）作為本系統最後使用之模型。模型的訓練與建置我們使用 Python 的 Scikit-learn（SKlearn）套件來實作。
2.3.1 OneVsRest
　　解決多標籤分類問題的其中一種方法為「問題轉換」，由於大多數傳統學習算法都是針對單標籤分類問題開發的，該類方法的思路是通過將多標籤問題轉換為多個單標籤問題，使其適應現有的單標籤算法來進行求解。
　　我們將多標籤問題分解成多個獨立的二元分類問題（每個類別一個），並且使用 OneVsRest（OneVsAll）的分類策略，構建多個獨立的分類器，並把受測資料分配到機率最高的類別中。這部分的分類方法使用 SVM（Support Vector Machine）中的 LinearSVC 分類模式。
2.3.2 Binary Relevance
　　Binary Relevance 同樣把每個標籤當作獨立的二元分類問題，每個分類器可以以「是」或「否」來回答「是否屬於該類別？」這個問題，OneVsRest 和 Binary Relevance 看起來非常相似，同樣也忽略了類別標籤之間可能的相關性。這部分的分類方法使用 Naïve Bayes 分類器中的MultinomialNB 算法。
2.3.3 Classifier Chains
　　Classifier Chains 即一系列的二元分類器，第一個分類器只在輸入數據上進行訓練，然後每個分類器都在輸入空間和鏈上的所有之前的分類器上進行訓練。這與前述的方法同樣會產生跟標籤總數相同的分類器，但是該方法考慮了類別標籤之間可能的相關性。這部分的分類方法使用 Naïve Bayes 分類器中的 MultinomialNB 算法。


2.3.4 Label Powerset
　　Label Powerset 將多標籤問題轉化為多類別分類問題，根據每個訓練樣本所擁有的標籤將訓練集中的每一個可能的標籤組合轉換為一個獨特的類別，例如：x1和 x4 同樣擁有 y1 和 y3 的標籤，x2 則擁有 y1 和 y2 的標籤，則 x1 和 x4 會被歸類為新的 y1 類別，x2 則被歸類為新的 y2類別。雖然該方法考慮了類別標籤之間的可能相關性，但是當類別數量增加時，不同標籤組合的數量可能呈指數增長，容易導致組合過多，從而導致計算無法負荷。這部分的分類方法使用 Naïve Bayes 分類器中的 MultinomialNB 算法。
2.3.5 ML-kNN
　　解決多標籤分類問題的另一種方法為
「改編算法」，透過改變單標籤分類算法來適配到多標籤的情況，而不是將問題轉化為不同的問題子集。 
　　ML-kNN 是從傳統的 kNN 算法中導出的，借鑑了 kNN 尋找 k 個近鄰訓練樣本的概念，並運用貝氏定理來計算當前標籤為 1 和 0 的機率，機率大的標籤定為樣本最終的標籤。本次研究我們將 k 設定為 5。
3. SYSTEM OUTCOME
　　本系統的結果主要以網站表現，呈現出主要的政治人物和政黨於特定時段內在 PTT 政黑版的聲量，並顯示出各立場推文次數前五高的使用者 ID 和推文內容。
3.1 系統採用模型
　　我們將比較前述所使用的多標籤分類方法，找出分類預測表現最好的模型來作為本研究系統模型使用，讓預測分析結果更具可信度與可靠性。
　　訓練模型時我們將總計 12,000 則的推文拆分成 75% 的訓練集和 25% 的測試集，以評估各分類器的表現（準確度），如表 1. 所示。
Classifier
Accuracy
OneVsRest
0.8335
Binary Relevance
0.713
Classifier Chains
0.7145
Label Powerset
0.7135
ML-kNN (k=5)
0.779
表 1. 各分類器表現分析表
　　從表 1.可以得知使用 OneVsRest 的分類策略，且使用 SVM 中的 LinearSVC 分類模式的準確度為最高，因此我們決定採用這個模型來做後續的分類預測。效率方面，Classifier Chains 跟 ML-kNN 所需的計算時間較長。
3.2 系統Demo
　　我們用於呈現的資料為 2020 中華民國總統選舉前 20 天（2019 年 12 月 21 號到 2020 年 1 月 10 號）的 PTT 政黑版所有文章的推文，總共有 423,238 筆推文。其中被分類為「有效分類」（即標籤值分類結果為 1~14）的推文有 27,598 筆，由於單筆推文可能存在 2 個標籤，擁有2個標籤的推文會同時屬於兩個分類，所以各分類所屬推文總數為 29,097 則，分類結果詳列於表 2.。若想觀看 Demo Clip可以前往： https://youtu.be/OlN4d00aBdY 
標籤值
代表意涵
數量
1
柯文哲 fans
30
2
柯文哲 haters
6,842
3
韓國瑜 fans
196
4
韓國瑜 haters
9,779
5
蔡英文 fans
225
6
蔡英文 haters
2,301
7
國民黨 fans
1
8
國民黨 haters
1,001
9
民進黨 fans
9
10
民進黨 haters
4,212
11
台灣民眾黨 fans
315
12
台灣民眾黨 haters
1,179
13
時代力量fans
3,007
14
時代力量haters
0




29,097
表 2. 應用於呈現資料的分類結果
4. CONCLUSION
　　本次研究藉由分析每個使用者的政治光譜，來觀察各政黨陣營的正負聲量，根據我們的統計結果，以柯文哲 haters（柯黑）、韓國瑜 haters（韓黑）、台灣民眾黨 haters（台民黨黑）數量最多。
      再者，我們也發現在 PTT 中，使用者們傾向以「謾罵代替鼓勵」，含有正面情緒的推文數量比起負面情緒的推文少很多，以內容來說正面情緒的推文所用的詞彙往往也比負面情緒推文來得單調，例如正面推文會使用「支持」、「加油」、「推」，但負面推文的批評詞彙量卻十分多樣化且為數眾多，也不乏一些具有創意性的新造詞語。
     另外，我們也發現推文中會有許多貼標籤、反串、嘲諷、引言的狀況，例如許多使用者會留言「柯粉：」加上一段他們認為「柯粉」會講的話，以模仿他們講話的樣子來達到調侃該族群的目的，這種特殊的句子結構也造成了分類上的困難。
     我們認為本次研究還有以下部分需要更精進：首先是「語意分析」，如上述，PTT 推文中存在較複雜的語句架構、隱喻意涵、筆戰內容較難單就詞頻分類，需考量語句前後，甚至前後推文、整篇文章的脈絡，然而本次研究所採用的分類器較難針對此種資料進行分析，人工標記上對於此種資料也較難達到共識。其次，更完整的訓練集也有助於提升分類的效果，本次受限於時間及人力成本，我們僅用了12,000 筆資料作為訓練集，在分類準則上雖然有事先達到共識，但還是存在一些位於分類模糊邊界的資料，因此在分類準則的制定上也有待加強。最後，由於 PTT 中許多使用者的留言往往跟時事有高度的連結性，負責標記的人員也需要時常關注時事，才能做到準確的分類。PTT 中產生流行語、新造詞的速度也非常快，本研究的訓練集取得的時間為 2019 年 12 月中旬，當時還沒有公布候選人號次，但用於呈現的資料中常常可以發現推文中出現候選人號次，針對此種資料，若無其他候選人相關詞彙出現，可能就會造成分類結果錯誤。因此我們認為在 PTT 的推文分析研究中，如果能夠定期更新訓練集，可以學習出更貼近現況的分類器。
5. REFERENCES
https://scikit-learn.org/stable/
https://github.com/APCLab/jieba-tw
http://scikit.ml/api/skmultilearn.adapt.mlknn.html
https://medium.com/ai反斗城/learning-model-multi-lable-classification-74d2799ff395
https://medium.com/@chih.sheng.huang821/機器學習-如何在多類別分類問題上使用用二元分類器進行分類-multiclass-strategy-for-binary-classifier-b4e5017202ff
6. WORKLOAD
莊雅媜
資料標籤、模型建立、報告撰寫
徐薇尹 
資料爬蟲、資料標籤、網站架設、自定義字典建立、報告撰寫
陳曦
資料標籤、報告撰寫、文獻探討
